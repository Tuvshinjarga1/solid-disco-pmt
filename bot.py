import os
import sys
import json
import traceback
from dataclasses import asdict

from botbuilder.core import MemoryStorage, TurnContext
from teams import Application, ApplicationOptions, TeamsAdapter
from teams.ai import AIOptions
from teams.ai.models import AzureOpenAIModelOptions, OpenAIModel, OpenAIModelOptions
from teams.ai.planners import ActionPlanner, ActionPlannerOptions
from teams.ai.prompts import PromptManager, PromptManagerOptions
from teams.state import TurnState
from teams.feedback_loop_data import FeedbackLoopData

from config import Config

config = Config()

# Create AI components
model: OpenAIModel

model = OpenAIModel(
    OpenAIModelOptions(
        api_key=config.OPENAI_API_KEY,
        default_model=config.OPENAI_MODEL_NAME,
    )
)

prompts = PromptManager(PromptManagerOptions(prompts_folder=f"{os.getcwd()}/prompts"))

planner = ActionPlanner(
    ActionPlannerOptions(
        model=model,
        prompts=prompts,
        default_prompt="chat",
        enable_feedback_loop=True,
    )
)

# Development mode configuration
if config.DEVELOPMENT_MODE:
    print("üß™ Development mode enabled - authentication bypass")
    # Development-–¥ Teams adapter “Ø“Ø—Å–≥—ç—Ö–≥“Ø–π
    storage = MemoryStorage()
    bot_app = None  # Teams framework –∞—à–∏–≥–ª–∞—Ö–≥“Ø–π
    
else:
    # Production mode - Full Teams AI framework
    print("üöÄ Production mode - Full Teams authentication")
    storage = MemoryStorage()
    bot_app = Application[TurnState](
        ApplicationOptions(
            bot_app_id=config.APP_ID,
            storage=storage,
            adapter=TeamsAdapter(config),
            ai=AIOptions(planner=planner, enable_feedback_loop=True),
        )
    )

# FastAPI Request-–≥ Teams AI bot-–¥ –¥–∞–º–∂—É—É–ª–∞—Ö
async def process_fastapi_request(fastapi_request):
    """FastAPI Request-–≥ Teams AI framework —Ä“Ø“Ø –¥–∞–º–∂—É—É–ª–∞—Ö"""
    try:
        if config.DEVELOPMENT_MODE or bot_app is None:
            # Development mode - Teams framework –∞—à–∏–≥–ª–∞—Ö–≥“Ø–π
            print("Development mode: Teams framework bypassed")
            return {"status": "development_mode", "message": "Use /api/test endpoint for testing"}
            
        # Production mode - Teams AI framework –∞—à–∏–≥–ª–∞—Ö
        response = await bot_app.process(fastapi_request)
        return response
        
    except Exception as e:
        print(f"Error processing FastAPI request: {e}")
        traceback.print_exc()
        return None

# Development test mode - Authentication-–≥“Ø–π–≥—ç—ç—Ä OpenAI —Ö–∞—Ä–∏—É –∞–≤–∞—Ö
async def handle_test_message(user_message: str) -> str:
    """Development test mode - Bot Framework-–≥“Ø–π–≥—ç—ç—Ä OpenAI-—Ç–∞–π —à—É—É–¥ —è—Ä–∏–ª—Ü–∞—Ö"""
    try:
        # OpenAI 1.0+ client –∞—à–∏–≥–ª–∞—Ö
        from openai import AsyncOpenAI
        
        # AsyncOpenAI client “Ø“Ø—Å–≥—ç—Ö  
        client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)
        
        # Chat completion —Ö“Ø—Å—ç–ª—Ç –∏–ª–≥—ç—ç—Ö
        response = await client.chat.completions.create(
            model=config.OPENAI_MODEL_NAME,
            messages=[
                {
                    "role": "system", 
                    "content": "–¢–∞ —Ç—É—Å–ª–∞—Ö AI –¥—ç–¥ —é–º. –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É. –ù–∞–π—Ä—Å–∞–≥, —Ç—É—Å–ª–∞–º–∂—Ç–∞–π –±–∞–π–≥–∞–∞—Ä–∞–π."
                },
                {
                    "role": "user", 
                    "content": user_message
                }
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        # Response-–æ–æ—Å —Ö–∞—Ä–∏—É–≥ –∞–≤–∞—Ö
        bot_response = response.choices[0].message.content.strip()
        return bot_response
        
    except Exception as e:
        print(f"Error in test mode: {e}")
        traceback.print_exc()
        return f"OpenAI API –∞–ª–¥–∞–∞: {str(e)}"

# Microsoft Teams activity format –æ–π–ª–≥–æ—Ö 
async def handle_teams_message(user_message: str, teams_activity: dict) -> str:
    """Microsoft Teams activity-–≥ –æ–π–ª–≥–æ–∂, OpenAI —à—É—É–¥ –∞—à–∏–≥–ª–∞—Ö"""
    try:
        # OpenAI 1.0+ client –∞—à–∏–≥–ª–∞—Ö
        from openai import AsyncOpenAI
        
        # Teams activity-–∞–∞—Å context –º—ç–¥—ç—ç–ª—ç–ª –∞–≤–∞—Ö
        user_name = teams_activity.get("from", {}).get("name", "User")
        conversation_id = teams_activity.get("conversation", {}).get("id", "unknown")
        
        # AsyncOpenAI client “Ø“Ø—Å–≥—ç—Ö  
        client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)
        
        # Teams context-—Ç—ç–π system prompt
        system_prompt = f"""
–¢–∞ Microsoft Teams-–¥ –∞–∂–∏–ª–ª–∞–¥–∞–≥ —Ç—É—Å–ª–∞—Ö AI bot —é–º. 
–•—ç—Ä—ç–≥–ª—ç–≥—á—Ç—ç–π {user_name} –≥—ç–∂ –Ω—ç—Ä–ª—ç–¥—ç–≥.
–ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä –Ω–∞–π—Ä—Å–∞–≥, —Ç—É—Å–ª–∞–º–∂—Ç–∞–π —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É.
Teams –æ—Ä—á–∏–Ω–¥ –∞–∂–∏–ª–ª–∞–∂ –±–∞–π–≥–∞–∞–≥–∞–∞ —Å–∞–Ω–∞–∞—Ä–∞–π.
"""
        
        # Chat completion —Ö“Ø—Å—ç–ª—Ç –∏–ª–≥—ç—ç—Ö
        response = await client.chat.completions.create(
            model=config.OPENAI_MODEL_NAME,
            messages=[
                {
                    "role": "system", 
                    "content": system_prompt
                },
                {
                    "role": "user", 
                    "content": user_message
                }
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        # Response-–æ–æ—Å —Ö–∞—Ä–∏—É–≥ –∞–≤–∞—Ö
        bot_response = response.choices[0].message.content.strip()
        
        # Teams activity logging
        print(f"üì¢ Teams message from {user_name}: {user_message}")
        print(f"ü§ñ Bot response: {bot_response}")
        
        return bot_response
        
    except Exception as e:
        print(f"Error in Teams message handling: {e}")
        traceback.print_exc()
        return f"Teams OpenAI –∞–ª–¥–∞–∞: {str(e)}"

# Teams AI framework event handlers (–∑”©–≤—Ö”©–Ω production mode-–¥)
if not config.DEVELOPMENT_MODE and bot_app is not None:
    @bot_app.error
    async def on_error(context: TurnContext, error: Exception):
        # This check writes out errors to console log .vs. app insights.
        # NOTE: In production environment, you should consider logging this to Azure
        #       application insights.
        print(f"\n [on_turn_error] unhandled error: {error}", file=sys.stderr)
        traceback.print_exc()

        # Send a message to the user
        await context.send_activity("The agent encountered an error or bug.")

    @bot_app.feedback_loop()
    async def feedback_loop(_context: TurnContext, _state: TurnState, feedback_loop_data: FeedbackLoopData):
        # Add custom feedback process logic here.
        print(f"Your feedback is:\n{json.dumps(asdict(feedback_loop_data), indent=4)}")

else:
    print("üß™ Development mode: Teams AI event handlers disabled")