import os
import sys
import json
import traceback
from dataclasses import asdict
import aiohttp

from botbuilder.core import MemoryStorage, TurnContext
from teams import Application, ApplicationOptions, TeamsAdapter
from teams.ai import AIOptions
from teams.ai.models import AzureOpenAIModelOptions, OpenAIModel, OpenAIModelOptions
from teams.ai.planners import ActionPlanner, ActionPlannerOptions
from teams.ai.prompts import PromptManager, PromptManagerOptions
from teams.state import TurnState
from teams.feedback_loop_data import FeedbackLoopData

from config import Config

config = Config()

# Create AI components
model: OpenAIModel

model = OpenAIModel(
    OpenAIModelOptions(
        api_key=config.OPENAI_API_KEY,
        default_model=config.OPENAI_MODEL_NAME,
    )
)

prompts = PromptManager(PromptManagerOptions(prompts_folder=f"{os.getcwd()}/prompts"))

planner = ActionPlanner(
    ActionPlannerOptions(
        model=model,
        prompts=prompts,
        default_prompt="chat",
        enable_feedback_loop=True,
    )
)

# Development mode configuration
if config.DEVELOPMENT_MODE:
    print("üß™ Development mode enabled - authentication bypass")
    # Development-–¥ Teams adapter “Ø“Ø—Å–≥—ç—Ö–≥“Ø–π
    storage = MemoryStorage()
    bot_app = None  # Teams framework –∞—à–∏–≥–ª–∞—Ö–≥“Ø–π
    
else:
    # Production mode - Full Teams AI framework
    print("üöÄ Production mode - Full Teams authentication")
    storage = MemoryStorage()
    bot_app = Application[TurnState](
        ApplicationOptions(
            bot_app_id=config.APP_ID,
            storage=storage,
            adapter=TeamsAdapter(config),
            ai=AIOptions(planner=planner, enable_feedback_loop=True),
        )
    )

# FastAPI Request-–≥ Teams AI bot-–¥ –¥–∞–º–∂—É—É–ª–∞—Ö
async def process_fastapi_request(fastapi_request):
    """FastAPI Request-–≥ Teams AI framework —Ä“Ø“Ø –¥–∞–º–∂—É—É–ª–∞—Ö"""
    try:
        if config.DEVELOPMENT_MODE or bot_app is None:
            # Development mode - Teams framework –∞—à–∏–≥–ª–∞—Ö–≥“Ø–π
            print("Development mode: Teams framework bypassed")
            return {"status": "development_mode", "message": "Use /api/test endpoint for testing"}
            
        # Production mode - Teams AI framework –∞—à–∏–≥–ª–∞—Ö
        response = await bot_app.process(fastapi_request)
        return response
        
    except Exception as e:
        print(f"Error processing FastAPI request: {e}")
        traceback.print_exc()
        return None

# Development test mode - Authentication-–≥“Ø–π–≥—ç—ç—Ä OpenAI —Ö–∞—Ä–∏—É –∞–≤–∞—Ö
async def handle_test_message(user_message: str) -> str:
    """Development test mode - Bot Framework-–≥“Ø–π–≥—ç—ç—Ä OpenAI-—Ç–∞–π —à—É—É–¥ —è—Ä–∏–ª—Ü–∞—Ö"""
    try:
        # OpenAI 1.0+ client –∞—à–∏–≥–ª–∞—Ö
        from openai import AsyncOpenAI
        
        # AsyncOpenAI client “Ø“Ø—Å–≥—ç—Ö  
        client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)
        
        # Chat completion —Ö“Ø—Å—ç–ª—Ç –∏–ª–≥—ç—ç—Ö
        response = await client.chat.completions.create(
            model=config.OPENAI_MODEL_NAME,
            messages=[
                {
                    "role": "system", 
                    "content": "–¢–∞ —Ç—É—Å–ª–∞—Ö AI –¥—ç–¥ —é–º. –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É. –ù–∞–π—Ä—Å–∞–≥, —Ç—É—Å–ª–∞–º–∂—Ç–∞–π –±–∞–π–≥–∞–∞—Ä–∞–π."
                },
                {
                    "role": "user", 
                    "content": user_message
                }
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        # Response-–æ–æ—Å —Ö–∞—Ä–∏—É–≥ –∞–≤–∞—Ö
        bot_response = response.choices[0].message.content.strip()
        return bot_response
        
    except Exception as e:
        print(f"Error in test mode: {e}")
        traceback.print_exc()
        return f"OpenAI API –∞–ª–¥–∞–∞: {str(e)}"

# Teams Bot Connector API –∞—à–∏–≥–ª–∞–∂ reply –∏–ª–≥—ç—ç—Ö
async def send_teams_reply(service_url: str, conversation_id: str, activity_id: str, bot_response: str, app_id: str = None):
    """Teams Bot Connector API –∞—à–∏–≥–ª–∞–∂ —Ö–∞—Ä–∏—É –∏–ª–≥—ç—ç—Ö"""
    try:
        # Reply URL “Ø“Ø—Å–≥—ç—Ö
        reply_url = f"{service_url}v3/conversations/{conversation_id}/activities/{activity_id}"
        
        # Reply activity “Ø“Ø—Å–≥—ç—Ö
        reply_activity = {
            "type": "message",
            "text": bot_response,
            "from": {
                "id": app_id or config.APP_ID or "bot-dev",
                "name": "Teams AI Bot"
            },
            "replyToId": activity_id
        }
        
        # HTTP client –∞—à–∏–≥–ª–∞–∂ Teams Bot Connector API –¥—É—É–¥–∞—Ö
        async with aiohttp.ClientSession() as session:
            # Development mode-–¥ authentication header-–≥“Ø–π–≥—ç—ç—Ä –æ—Ä–æ–ª–¥–æ—Ö
            headers = {
                "Content-Type": "application/json"
            }
            
            # Production mode-–¥ Bearer token —Ö—ç—Ä—ç–≥—Ç—ç–π (–æ–¥–æ–æ—Ö–æ–Ω–¥–æ–æ —Ö–æ–æ—Å–æ–Ω)
            if not config.DEVELOPMENT_MODE and config.APP_ID:
                headers["Authorization"] = f"Bearer {config.APP_ID}"  # Simplified for dev
            
            print(f"üîó Sending reply to: {reply_url}")
            print(f"üì§ Reply activity: {json.dumps(reply_activity, indent=2)}")
            
            async with session.post(reply_url, json=reply_activity, headers=headers) as response:
                if response.status == 200 or response.status == 201:
                    print("‚úÖ Teams reply sent successfully!")
                    return True
                else:
                    response_text = await response.text()
                    print(f"‚ùå Teams reply failed: {response.status} - {response_text}")
                    return False
                    
    except Exception as e:
        print(f"Error sending Teams reply: {e}")
        traceback.print_exc()
        return False

# Microsoft Teams activity format –æ–π–ª–≥–æ—Ö 
async def handle_teams_message(user_message: str, teams_activity: dict) -> dict:
    """Microsoft Teams activity-–≥ –æ–π–ª–≥–æ–∂, OpenAI —à—É—É–¥ –∞—à–∏–≥–ª–∞—Ö, Teams reply –∏–ª–≥—ç—ç—Ö"""
    try:
        # OpenAI 1.0+ client –∞—à–∏–≥–ª–∞—Ö
        from openai import AsyncOpenAI
        
        # Teams activity-–∞–∞—Å context –º—ç–¥—ç—ç–ª—ç–ª –∞–≤–∞—Ö
        user_name = teams_activity.get("from", {}).get("name", "User")
        conversation_id = teams_activity.get("conversation", {}).get("id", "unknown")
        activity_id = teams_activity.get("id", "unknown")
        service_url = teams_activity.get("serviceUrl", "")
        
        # AsyncOpenAI client “Ø“Ø—Å–≥—ç—Ö  
        client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)
        
        # Teams context-—Ç—ç–π system prompt
        system_prompt = f"""
–¢–∞ Microsoft Teams-–¥ –∞–∂–∏–ª–ª–∞–¥–∞–≥ —Ç—É—Å–ª–∞—Ö AI bot —é–º. 
–•—ç—Ä—ç–≥–ª—ç–≥—á—Ç—ç–π {user_name} –≥—ç–∂ –Ω—ç—Ä–ª—ç–¥—ç–≥.
–ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä –Ω–∞–π—Ä—Å–∞–≥, —Ç—É—Å–ª–∞–º–∂—Ç–∞–π —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É.
Teams –æ—Ä—á–∏–Ω–¥ –∞–∂–∏–ª–ª–∞–∂ –±–∞–π–≥–∞–∞–≥–∞–∞ —Å–∞–Ω–∞–∞—Ä–∞–π.
"""
        
        # Chat completion —Ö“Ø—Å—ç–ª—Ç –∏–ª–≥—ç—ç—Ö
        response = await client.chat.completions.create(
            model=config.OPENAI_MODEL_NAME,
            messages=[
                {
                    "role": "system", 
                    "content": system_prompt
                },
                {
                    "role": "user", 
                    "content": user_message
                }
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        # Response-–æ–æ—Å —Ö–∞—Ä–∏—É–≥ –∞–≤–∞—Ö
        bot_response = response.choices[0].message.content.strip()
        
        # Teams activity logging
        print(f"üì¢ Teams message from {user_name}: {user_message}")
        print(f"ü§ñ Bot response: {bot_response}")
        
        # Teams client —Ä“Ø“Ø reply –∏–ª–≥—ç—ç—Ö
        reply_success = False
        if service_url and conversation_id and activity_id:
            reply_success = await send_teams_reply(
                service_url=service_url,
                conversation_id=conversation_id, 
                activity_id=activity_id,
                bot_response=bot_response
            )
        
        return {
            "bot_response": bot_response,
            "reply_sent": reply_success,
            "teams_context": {
                "user": user_name,
                "conversation_id": conversation_id,
                "activity_id": activity_id,
                "service_url": service_url
            }
        }
        
    except Exception as e:
        print(f"Error in Teams message handling: {e}")
        traceback.print_exc()
        return {
            "bot_response": f"Teams OpenAI –∞–ª–¥–∞–∞: {str(e)}",
            "reply_sent": False,
            "error": str(e)
        }

# Teams AI framework event handlers (–∑”©–≤—Ö”©–Ω production mode-–¥)
if not config.DEVELOPMENT_MODE and bot_app is not None:
    @bot_app.error
    async def on_error(context: TurnContext, error: Exception):
        # This check writes out errors to console log .vs. app insights.
        # NOTE: In production environment, you should consider logging this to Azure
        #       application insights.
        print(f"\n [on_turn_error] unhandled error: {error}", file=sys.stderr)
        traceback.print_exc()

        # Send a message to the user
        await context.send_activity("The agent encountered an error or bug.")

    @bot_app.feedback_loop()
    async def feedback_loop(_context: TurnContext, _state: TurnState, feedback_loop_data: FeedbackLoopData):
        # Add custom feedback process logic here.
        print(f"Your feedback is:\n{json.dumps(asdict(feedback_loop_data), indent=4)}")

else:
    print("üß™ Development mode: Teams AI event handlers disabled")